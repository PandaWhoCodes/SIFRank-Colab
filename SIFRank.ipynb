{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIFRank.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ3xtSrosr7e",
        "colab_type": "text"
      },
      "source": [
        "# Downloading\n",
        "- Code\n",
        "- Pretrained weight files\n",
        "- Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbS2NQhDqY_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install allennlp==0.9.0\n",
        "!pip install stanza==1.0.0\n",
        "!git clone https://github.com/PandaWhoCodes/SIFRank-Colab\n",
        "%cd SIFRank-Colab/data\n",
        "!wget https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\n",
        "%cd ../"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ld0Sy2BtApL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "4e809435-d68a-41bf-b255-2e8761b6076b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet') \n",
        "import stanza\n",
        "stanza.download('en')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 18.5MB/s]                    \n",
            "2020-07-09 03:53:24 INFO: Downloading default packages for language: en (English)...\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.0.0/en/default.zip: 100%|██████████| 402M/402M [02:54<00:00, 2.30MB/s]\n",
            "2020-07-09 03:56:27 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEbR7R-1shWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from embeddings import sent_emb_sif, word_emb_elmo\n",
        "from model.method import SIFRank, SIFRank_plus\n",
        "import stanza\n",
        "\n",
        "# download from https://allennlp.org/elmo\n",
        "options_file = \"data/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "weight_file = \"data/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAaeLXXStD14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "9217aeba-70ea-4608-c4f1-9f14ce67df9f"
      },
      "source": [
        "porter = nltk.PorterStemmer()\n",
        "ELMO = word_emb_elmo.WordEmbeddings(options_file, weight_file, cuda_device=0)\n",
        "SIF = sent_emb_sif.SentEmbeddings(ELMO,\"data/\", lamda=1.0)\n",
        "en_model = stanza.Pipeline(lang='en', processors={}, use_gpu=True)\n",
        "elmo_layers_weight = [0.0, 1.0, 0.0]\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-09 03:56:56 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | ewt       |\n",
            "| pos       | ewt       |\n",
            "| lemma     | ewt       |\n",
            "| depparse  | ewt       |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2020-07-09 03:56:56 INFO: Use device: gpu\n",
            "2020-07-09 03:56:56 INFO: Loading: tokenize\n",
            "2020-07-09 03:56:56 INFO: Loading: pos\n",
            "2020-07-09 03:56:57 INFO: Loading: lemma\n",
            "2020-07-09 03:56:57 INFO: Loading: depparse\n",
            "2020-07-09 03:56:58 INFO: Loading: ner\n",
            "2020-07-09 03:56:59 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBzMFs-wtGY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"\"\"Companies like Netflix, Amazon, and Spotify are raising the bar on consumer expectations for personalized experiences. These companies are using technologies like artificial intelligence (AI) to provide customized recommendations to subscribers and customers in real-time. Consumers have come to appreciate this approach and now expect other brands — including publishers — to cater to their individual preferences.\n",
        "\n",
        "Responding to consumer expectations, publishers are embracing AI to tailor content to their readers across distribution channels with the aim of increasing audience engagement, growing readership, and boosting ad revenue. Some areas where AI is proving specifically helpful for publishers include content categorization, data-driven content personalization, and targeted marketing.\n",
        "\n",
        "Content Categorization\n",
        "AI and machine learning (ML) technology are being used to classify content to make it more easily sortable and searchable. By optimizing the accuracy of search results, publishers can boost content visibility and engagement. Large publishers, in particular, are increasingly relying on this application of AI to meet the challenge of classifying and organizing the sheer volume of content they’ve been creating for years.\n",
        "\n",
        "AI technology allows publishers to scan an article and create tags based on the content to apply structure to unstructured information and make content easier to find and use. This process can also be applied to images, video, and audio. Additional technologies like speech-to-text, ML, and visual recognition software are making images, video, and audio more discoverable than ever.\n",
        "\n",
        "Better organized content is easier for publishers to repackage and monetize with readers and advertisers. Because it's easier to sort and search, publishers are able to mine their archives to compile special anniversary issues or themed collections that give existing content new life, providing monetization opportunities and value to readers.\n",
        "\n",
        "Data-Driven Content Personalization\n",
        "One of the most significant ways publishers are using AI is by monitoring reader behavior and suggesting relevant content. A 2018 survey by the Reuters Institute for the Study of Journalism found that 60% of publishers use some form of AI to improve content recommendations.\n",
        "\n",
        "News outlets like The Wall Street Journal and The New York Times are taking a page out of Netflix’s book by using AI-powered recommendation engines to anticipate the content a specific reader is likely to engage with, and then serving related content to that reader accordingly. Through its My WSJ feature on mobile, The Wall Street Journal delivers a “recommended” list of stories to readers derived from their viewing history. The New York Times’ recommendation module, Editors’ Picks, uses contextual bandit tools to make article recommendations based on reader geographic location. These regionally relevant recommendations have allowed the Times to increase the click-through rate on the Editors’ Picks module by 55%.\n",
        "\n",
        "As audio becomes a preferred format for content consumption, publishers are also finding ways to use AI to custom-tailor user experiences with audio assets. For example, by analyzing the author name, audio content can be delivered to listeners in the gender of the content author. This application can even be extended to reading article content in the language of the listener.\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oTcguVZtMp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3ad4cb5c-f1ca-4f46-948a-94515de37eb1"
      },
      "source": [
        "keyphrases = SIFRank(text, SIF, en_model, N=15, elmo_layers_weight=elmo_layers_weight)\n",
        "keyphrases_ = SIFRank_plus(text, SIF, en_model, N=15, elmo_layers_weight=elmo_layers_weight)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6SATEcFtONS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61570d48-de26-4887-d703-0948223caf40"
      },
      "source": [
        "for keyword in keyphrases[0]:\n",
        "  print(keyword)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reader behavior\n",
            "content categorization\n",
            "content visibility\n",
            "relevant content\n",
            "article content\n",
            "content categorization ai\n",
            "monetization opportunities\n",
            "audio content\n",
            "content personalization\n",
            "content recommendations\n",
            "recommendation engines\n",
            "contextual bandit tools\n",
            "related content\n",
            "content consumption\n",
            "visual recognition software\n",
            "distribution channels\n",
            "reader geographic location\n",
            "ai technology\n",
            "advertiser\n",
            "unstructured information\n",
            "content\n",
            "user experiences\n",
            "audience engagement\n",
            "themed collections\n",
            "content author\n",
            "search results\n",
            "organized content\n",
            "content new life\n",
            "article\n",
            "recommendation module\n",
            "audio assets\n",
            "significant ways publishers\n",
            "article recommendations\n",
            "publisher\n",
            "recommendation\n",
            "author name\n",
            "reader\n",
            "technology\n",
            "archive\n",
            "large publishers\n",
            "experience\n",
            "readership\n",
            "subscriber\n",
            "relevant recommendations\n",
            "individual preferences\n",
            "special anniversary issues\n",
            "ad revenue\n",
            "customer\n",
            "format\n",
            "specific reader\n",
            "ai\n",
            "image\n",
            "additional technologies\n",
            "audio\n",
            "machine learning\n",
            "consumer expectations\n",
            "wsj feature\n",
            "marketing\n",
            "structure\n",
            "netflix\n",
            "application\n",
            "listener\n",
            "brand\n",
            "viewing history\n",
            "picks module\n",
            "artificial intelligence\n",
            "story\n",
            "video\n",
            "news outlets\n",
            "accuracy\n",
            "tag\n",
            "engagement\n",
            "data\n",
            "sheer volume\n",
            "editor\n",
            "text\n",
            "book\n",
            "approach\n",
            "spotify\n",
            "click\n",
            "speech\n",
            "language\n",
            "list\n",
            "ml\n",
            "challenge\n",
            "process\n",
            "wall street journal\n",
            "company\n",
            "pick\n",
            "value\n",
            "mobile\n",
            "area\n",
            "form\n",
            "amazon\n",
            "page\n",
            "way\n",
            "rate\n",
            "consumer\n",
            "survey\n",
            "journalism\n",
            "bar\n",
            "reuters institute\n",
            "gender\n",
            "new york times\n",
            "year\n",
            "time\n",
            "aim\n",
            "example\n",
            "study\n",
            "%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V5Egxh6tPi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a0e59e2-75b3-475a-e6a2-479a358c2fc1"
      },
      "source": [
        "for keyword in keyphrases_[0]:\n",
        "  print(keyword)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "netflix\n",
            "company\n",
            "reader behavior\n",
            "content categorization\n",
            "experience\n",
            "content visibility\n",
            "content categorization ai\n",
            "content personalization\n",
            "technology\n",
            "consumer expectations\n",
            "relevant content\n",
            "distribution channels\n",
            "recommendation\n",
            "article content\n",
            "monetization opportunities\n",
            "content\n",
            "audio content\n",
            "content recommendations\n",
            "audience engagement\n",
            "recommendation engines\n",
            "subscriber\n",
            "ai technology\n",
            "ai\n",
            "publisher\n",
            "visual recognition software\n",
            "spotify\n",
            "related content\n",
            "contextual bandit tools\n",
            "content consumption\n",
            "unstructured information\n",
            "advertiser\n",
            "reader geographic location\n",
            "customer\n",
            "search results\n",
            "reader\n",
            "user experiences\n",
            "themed collections\n",
            "organized content\n",
            "artificial intelligence\n",
            "article\n",
            "amazon\n",
            "individual preferences\n",
            "content new life\n",
            "content author\n",
            "readership\n",
            "significant ways publishers\n",
            "recommendation module\n",
            "audio assets\n",
            "large publishers\n",
            "ad revenue\n",
            "article recommendations\n",
            "author name\n",
            "archive\n",
            "brand\n",
            "relevant recommendations\n",
            "machine learning\n",
            "marketing\n",
            "special anniversary issues\n",
            "image\n",
            "specific reader\n",
            "audio\n",
            "additional technologies\n",
            "format\n",
            "structure\n",
            "application\n",
            "wsj feature\n",
            "bar\n",
            "approach\n",
            "listener\n",
            "viewing history\n",
            "picks module\n",
            "video\n",
            "data\n",
            "accuracy\n",
            "engagement\n",
            "story\n",
            "news outlets\n",
            "tag\n",
            "sheer volume\n",
            "text\n",
            "editor\n",
            "book\n",
            "ml\n",
            "speech\n",
            "challenge\n",
            "click\n",
            "consumer\n",
            "process\n",
            "area\n",
            "list\n",
            "language\n",
            "wall street journal\n",
            "pick\n",
            "value\n",
            "mobile\n",
            "form\n",
            "page\n",
            "way\n",
            "rate\n",
            "time\n",
            "survey\n",
            "journalism\n",
            "reuters institute\n",
            "aim\n",
            "gender\n",
            "year\n",
            "new york times\n",
            "example\n",
            "study\n",
            "%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Ka2b1xtRIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}